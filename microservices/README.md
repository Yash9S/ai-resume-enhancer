# AI Resume Parser - Microservices Architecture

## ğŸ—ï¸ Architecture Overview

This document outlines the migration from a Rails monolith to a microservices architecture.

### **Services:**

1. **ğŸ¤– AI Extraction Service** (`ai-extraction-service/`)
   - **Technology**: Python + FastAPI
   - **Purpose**: PDF/DOCX parsing, AI processing, content enhancement
   - **Port**: 8001

2. **ğŸ“Š Business Logic API** (`business-api/`)
   - **Technology**: Rails API-only
   - **Purpose**: User management, multi-tenancy, data persistence
   - **Port**: 3001

3. **ğŸ¨ Frontend Service** (`frontend/`)
   - **Technology**: React + Next.js
   - **Purpose**: User interface, file uploads, dashboard
   - **Port**: 3000

4. **ğŸ”Œ API Gateway** (`api-gateway/`)
   - **Technology**: Nginx or Node.js Express
   - **Purpose**: Request routing, authentication, load balancing
   - **Port**: 8080

### **Shared Infrastructure:**
- **Database**: PostgreSQL (shared or per-service)
- **Cache/Queue**: Redis
- **File Storage**: MinIO or AWS S3
- **Service Discovery**: Consul or built-in Docker networking

## ğŸš€ Migration Strategy

### Phase 1: Extract AI Service (Current)
1. Create Python FastAPI service
2. Move `ResumeParsingService` logic
3. Implement async processing
4. Test service isolation

### Phase 2: Refactor Rails API
1. Convert Rails to API-only mode
2. Remove AI processing logic
3. Create service-to-service communication
4. Maintain multi-tenancy

### Phase 3: Frontend Separation
1. Create React/Next.js app
2. Implement API integration
3. Migrate UI components
4. Handle authentication

### Phase 4: Production Deployment
1. Container orchestration
2. Service monitoring
3. API gateway setup
4. Database optimization

## ğŸ“ Directory Structure

```
microservices/
â”œâ”€â”€ ai-extraction-service/     # Python FastAPI service
â”œâ”€â”€ business-api/              # Rails API-only service
â”œâ”€â”€ frontend/                  # React/Next.js application
â”œâ”€â”€ api-gateway/               # Request routing
â”œâ”€â”€ shared/                    # Shared utilities and configs
â”œâ”€â”€ docker-compose.yml         # Development setup
â”œâ”€â”€ docker-compose.prod.yml    # Production setup
â””â”€â”€ README.md                  # This file
```

## ğŸ”„ Service Communication

```mermaid
graph TB
    A[Frontend] --> B[API Gateway]
    B --> C[Business API]
    B --> D[AI Extraction Service]
    C --> E[PostgreSQL]
    D --> F[Redis Queue]
    D --> G[File Storage]
```

## ğŸ› ï¸ Development Commands

```bash
# Start all services
docker-compose up

# Start specific service
docker-compose up ai-extraction-service

# View logs
docker-compose logs -f business-api

# Rebuild service
docker-compose up --build frontend
```

## ğŸ“Š Service Responsibilities

| Service | Authentication | File Processing | Data Persistence | Multi-tenancy |
|---------|---------------|-----------------|------------------|---------------|
| Frontend | âŒ | âœ… Upload | âŒ | âœ… Routing |
| Business API | âœ… | âŒ | âœ… | âœ… |
| AI Service | âŒ | âœ… Processing | âŒ | âŒ |
| API Gateway | âœ… Middleware | âŒ | âŒ | âœ… Routing |

## ğŸ¯ Benefits

- **Scalability**: Scale AI processing independently
- **Technology Choice**: Best tool for each job
- **Development Velocity**: Teams can work independently
- **Deployment**: Deploy services separately
- **Resilience**: Service isolation prevents cascading failures

## ğŸš¨ Considerations

- **Complexity**: More moving parts
- **Network Latency**: Service-to-service calls
- **Data Consistency**: Distributed transactions
- **Monitoring**: Need comprehensive observability